/**
 * SentinelQuant Scheduled Automation
 * Uses node-cron to run background tasks
 * Pipeline: scrape ‚Üí analyze sentiment ‚Üí aggregate daily ‚Üí notify
 */

const cron = require('node-cron');
const { runAllScrapers } = require('./scrapers/newsScraper');
const { analyzeUnprocessedArticles } = require('./services/sentimentService');
const { query } = require('./db');
const { broadcastScrapeComplete, broadcastSentimentUpdate } = require('./socket');

// Log that cron is starting
console.log('‚è∞ Initializing Automated Tasks (Cron Jobs)...');

// Read interval from env, default to every 15 minutes if not specified
const scrapeInterval = process.env.SCRAPE_INTERVAL_MINUTES || 15;
const cronSchedule = `*/${scrapeInterval} * * * *`;

/**
 * Aggregate today's sentiment scores into the daily_sentiment table.
 * This enables the StockDetail history chart to display trends over time.
 */
async function aggregateDailySentiment() {
    try {
        await query(`
            INSERT INTO daily_sentiment (
                stock_id, date,
                avg_sentiment, weighted_sentiment,
                article_count,
                positive_count, negative_count, neutral_count
            )
            SELECT
                ss.stock_id,
                CURRENT_DATE,
                AVG(ss.raw_score),
                AVG(ss.raw_score),
                COUNT(*),
                COUNT(*) FILTER (WHERE ss.sentiment = 'positive'),
                COUNT(*) FILTER (WHERE ss.sentiment = 'negative'),
                COUNT(*) FILTER (WHERE ss.sentiment = 'neutral')
            FROM sentiment_scores ss
            WHERE DATE(ss.analyzed_at) = CURRENT_DATE
            GROUP BY ss.stock_id
            ON CONFLICT (stock_id, date) DO UPDATE SET
                avg_sentiment    = EXCLUDED.avg_sentiment,
                weighted_sentiment = EXCLUDED.weighted_sentiment,
                article_count    = EXCLUDED.article_count,
                positive_count   = EXCLUDED.positive_count,
                negative_count   = EXCLUDED.negative_count,
                neutral_count    = EXCLUDED.neutral_count
        `);
        console.log('üìä daily_sentiment aggregation complete.');
    } catch (err) {
        console.error('‚ö†Ô∏è  daily_sentiment aggregation failed:', err.message);
    }
}

/**
 * Generate notifications for users based on sentiment changes.
 */
async function generateNotifications(scrapeResult) {
    try {
        // Check for notable sentiment changes today
        const extremes = await query(`
            SELECT ds.stock_id, s.symbol, s.name, ds.weighted_sentiment
            FROM daily_sentiment ds
            JOIN stocks s ON ds.stock_id = s.id
            WHERE ds.date = CURRENT_DATE
              AND (ds.weighted_sentiment > 0.5 OR ds.weighted_sentiment < -0.5)
        `);

        if (extremes.rows.length > 0) {
            const users = await query('SELECT id FROM users');

            for (const stock of extremes.rows) {
                const isSurge = stock.weighted_sentiment > 0;
                const type = isSurge ? 'sentiment_surge' : 'sentiment_drop';
                const title = isSurge
                    ? `üìà ${stock.symbol} sentiment surging`
                    : `üìâ ${stock.symbol} sentiment dropping`;
                const message = `${stock.name} has a weighted sentiment score of ${(stock.weighted_sentiment * 100).toFixed(1)}%. ${isSurge ? 'Consider increasing allocation.' : 'Review your position.'}`;

                for (const user of users.rows) {
                    await query(`
                        INSERT INTO notifications (user_id, type, title, message)
                        SELECT $1, $2, $3, $4
                        WHERE NOT EXISTS (
                            SELECT 1 FROM notifications
                            WHERE user_id = $1 AND type = $2 AND title = $3
                              AND created_at >= CURRENT_DATE
                        )
                    `, [user.id, type, title, message]);
                }
            }
            console.log(`üîî Generated notifications for ${extremes.rows.length} notable stocks.`);
        }

        // Notify pro users about scrape completion
        if (scrapeResult && scrapeResult.new_articles > 0) {
            const proUsers = await query("SELECT id FROM users WHERE tier IN ('pro', 'enterprise')");
            for (const user of proUsers.rows) {
                await query(`
                    INSERT INTO notifications (user_id, type, title, message)
                    VALUES ($1, 'scrape_complete', 'üóûÔ∏è Pipeline complete',
                            $2)
                `, [
                    user.id,
                    `Scraped ${scrapeResult.new_articles} new articles, analyzed ${scrapeResult.analyzed_articles} for sentiment. Data updated.`
                ]);
            }
        }
    } catch (err) {
        console.error('‚ö†Ô∏è  Notification generation failed:', err.message);
    }
}

// Define the full pipeline job: scrape ‚Üí analyze ‚Üí aggregate ‚Üí notify
const pipelineJob = cron.schedule(cronSchedule, async () => {
    console.log(`\n==========================================`);
    console.log(`‚è±Ô∏è  [CRON TRIGGERED] Running full pipeline at ${new Date().toISOString()}`);
    console.log(`==========================================`);

    try {
        // Step 1: Scrape news from all sources
        const scrapeResult = await runAllScrapers();
        console.log(`üì∞ Scrape complete: ${scrapeResult.new_articles} new articles saved`);

        // Step 2: Run sentiment analysis on unprocessed articles
        let analyzedCount = 0;
        try {
            analyzedCount = await analyzeUnprocessedArticles();
            console.log(`üß† Sentiment analysis complete: ${analyzedCount} articles analyzed`);
        } catch (analyzeErr) {
            console.error(`‚ö†Ô∏è  Sentiment analysis failed: ${analyzeErr.message}`);
        }

        // Step 3: Aggregate into daily_sentiment for charting
        await aggregateDailySentiment();

        // Build truthful result summary
        const result = {
            ...scrapeResult,
            analyzed_articles: analyzedCount, // Actual analyzed count, not copied from saved
        };

        // Step 4: Generate notifications for users
        await generateNotifications(result);

        // Step 5: Broadcast via Socket.IO
        broadcastScrapeComplete(result);

        console.log(`‚úÖ Full pipeline complete: scraped=${scrapeResult.new_articles}, analyzed=${analyzedCount}`);
        console.log(`==========================================\n`);

    } catch (error) {
        console.error(`‚ùå Pipeline Failed:`, error.message);
    }
}, {
    scheduled: false
});

// Export a function to start all cron jobs
function startCronJobs() {
    console.log(`üïí Pipeline job scheduled to run every ${scrapeInterval} minutes.`);
    pipelineJob.start();
}

module.exports = { startCronJobs };
